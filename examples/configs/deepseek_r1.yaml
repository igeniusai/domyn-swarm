model: deepseek-ai/DeepSeek-R1-0528
name: deepseek-r1
revision: main
gpus_per_replica: 24
gpus_per_node: 4
replicas: 1
args: "--block-size 32 --enable-expert-parallel --reasoning-parser deepseek_r1 --pipeline-parallel-size 6  --dtype bfloat16 --gpu-memory-utilization 0.95 --max-model-len 32768 --max-num-seqs 128"
lb_wait: 3600
image: "/leonardo_work/iGen_train/fdambro1/images/vllm_0.11.0.sif"
env:
  HF_HOME: /leonardo_work/iGen_train/shared_hf_cache
backend:
  type: slurm
  partition: boost_usr_prod
  account: iGen_train
  qos: qos_llm_min
  endpoint:
    nginx_image: "/leonardo_work/iGen_train/fdambro1/images/nginx.sif"
    port: 9001
    cpus_per_task: 4
    wall_time: "36:00:00"
