model: Qwen/Qwen3-32B
revision: main
gpus_per_replica: 4
replicas: 4
wait_endpoint_s: 1800
hf_home: /leonardo_scratch/fast/iGen_train/shared_hf_cache/
args: "--reasoning-parser deepseek_r1 --pipeline-parallel-size 1 --gpu-memory-utilization 0.95 --max-num-seqs 256 --max-model-len 16384"
backend:
  type: slurm
  partition: boost_usr_prod
  account: igen_train
  qos: qos_llm_min
  endpoint:
    port: 9003
    mem: "16GB"
    cpus_per_task: 4
    wall_time: "100:00:00"
