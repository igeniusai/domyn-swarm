model: Qwen/Qwen3-32B
revision: main
nodes: 4
gpus_per_node: 4
replicas: 2
cpus_per_task: 12
lb_wait: 1800
lb_port: 9001
vllm_args: "--block-size 32 --reasoning-parser deepseek_r1 --pipeline-parallel-size 4  --dtype bfloat16 --gpu-memory-utilization 0.9 --max-num-seqs 128"
vllm_image: /leonardo_work/iGen_train/fdambro1/images/vllm_0.9.1.sif
hf_home: /leonardo_scratch/fast/iGen_train/shared_hf_cache/
